{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Union, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data.\n",
    "df = pd.read_csv('smoothed_data_kansas.csv')\n",
    "x = np.concatenate((df['x_19'], df['x_20'], df['x_22']), axis=0)\n",
    "# NDVI time series.\n",
    "y = np.concatenate((df['y_19'], df['y_20'], df['y_22']), axis=0)\n",
    "# Generate the time vector in days after planting.\n",
    "time = [i for i in range(len(y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('NDVI time series for Kansas')\n",
    "plt.plot(time, y, 'b', label='2019-2022')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series parameters.\n",
    "@dataclass\n",
    "class PARAMETERS:\n",
    "  TIME, SERIES = time, y\n",
    "  # Number of days to be used on the training set.\n",
    "  SPLIT_TIME = 200\n",
    "  # Data points to make our prediction.\n",
    "  WINDOW_SIZE = 25\n",
    "  # How many items will we supply per batch.\n",
    "  BATCH_SIZE = 32\n",
    "  # Define the Tensorflow sample buffer.\n",
    "  SHUFFLE_BUFFER_SIZE = 1000\n",
    "  # Number of epochs.\n",
    "  EPOCHS = 50\n",
    "  # Next t steps to predeict.\n",
    "  PREDICT_STEPS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(\n",
    "  time: Union[List, np.ndarray],\n",
    "  series: Union[List, np.ndarray],\n",
    "  time_step: int = PARAMETERS.SPLIT_TIME\n",
    ") -> Tuple[np.ndarray, ...]:\n",
    "  \"\"\"\n",
    "  Divide the time series into training and validation set.\n",
    "  \"\"\"\n",
    "  assert isinstance(time, (np.ndarray, list))\n",
    "  \n",
    "  # Training time vector.\n",
    "  time_train = time[:time_step]\n",
    "  # NDVI series vector.\n",
    "  series_train = series[:time_step]\n",
    "  # Validation time vector.\n",
    "  time_valid = time[time_step:]\n",
    "  # NDVI series vector.\n",
    "  series_valid = series[time_step:]\n",
    "  \n",
    "  return time_train, series_train, time_valid, series_valid\n",
    "\n",
    "def windowed_dataset(\n",
    "\tseries: Union[List, np.ndarray],\n",
    "\twindow_size: int = PARAMETERS.WINDOW_SIZE,\n",
    "\tbatch_size: int = PARAMETERS.BATCH_SIZE,\n",
    "\tshuffle_buffer: int = PARAMETERS.SHUFFLE_BUFFER_SIZE\n",
    ") -> tf.data.Dataset:\n",
    "\t\"\"\"\n",
    "\tWe create time windows to create X and y features.\n",
    "\tFor example, if we choose a window of 30, we will create a dataset formed by 30 points as X\n",
    "\t\"\"\"\n",
    "\t# Create a TensorFlow dataset from np.arrays or lists.\n",
    "\tdataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\t# Create a DataFrame of windows.\n",
    "\tdataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "\t# Flat the vectors and make batches of the data.\n",
    "\tdataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\t# Randomly shuffle the data.\n",
    "\tdataset = dataset.shuffle(shuffle_buffer)\n",
    "\t# Transform the data to the format X, y.\n",
    "\tdataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\t# Prefetch.\n",
    "\tdataset = dataset.batch(batch_size).prefetch(1)\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation set\n",
    "time_train, series_train, time_valid, series_valid = train_val_split(PARAMETERS.TIME, PARAMETERS.SERIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset with time windows.\n",
    "dataset = windowed_dataset(series_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('mae') < 0.03):\n",
    "      print(\"\\nMAEthreshold reached. Training stopped.\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Let's create an object of our class and assign it to a variable\n",
    "early_stopping = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \"\"\"\n",
    "  Function to define a sequential model.\n",
    "  Appropriate for a plain stack of layers where \n",
    "  each layer has exactly ONE input tensor and ONE output tensor.\n",
    "  \"\"\"\n",
    "  # Set a random seed.\n",
    "  tf.random.set_seed(51)\n",
    "\n",
    "  # Uncompiled model.\n",
    "  model = tf.keras.models.Sequential([\n",
    "      # Lambda layer to handle the input data format. \n",
    "      tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), \n",
    "                              input_shape=[None]),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024, return_sequences=True)),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "      # Layer of prediction.\n",
    "      tf.keras.layers.Dense(1),\n",
    "  ])\n",
    "  \n",
    "  # Compile model for training.\n",
    "  model.compile(\n",
    "    loss=tf.keras.losses.Huber(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['mae']\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call and create the model.\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and assign the callback\n",
    "history = model.fit(dataset, epochs=PARAMETERS.EPOCHS, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "  true_series : Union[List, np.ndarray],\n",
    "  forecast : Union[List, np.ndarray]\n",
    ") -> Tuple[float, float]:\n",
    "  \"\"\"\n",
    "  Print MSE and MAE\n",
    "  \"\"\"\n",
    "  mse = tf.keras.metrics.mean_squared_error(true_series, forecast).numpy()\n",
    "  mae = tf.keras.metrics.mean_absolute_error(true_series, forecast).numpy()\n",
    "\n",
    "  return mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(\n",
    "  model, \n",
    "  series: np.ndarray, \n",
    "  window_size: int\n",
    ") -> np.ndarray:\n",
    "  \"\"\"\n",
    "  Converts the input series into a dataset with time windows for forecasting.\n",
    "  \"\"\"\n",
    "  ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "  ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "  ds = ds.flat_map(lambda w: w.batch(window_size))\n",
    "  ds = ds.batch(32).prefetch(1)\n",
    "  forecast = model.predict(ds)\n",
    "  \n",
    "  return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the whole series.\n",
    "all_forecast = model_forecast(model, PARAMETERS.SERIES, PARAMETERS.WINDOW_SIZE).squeeze()\n",
    "\n",
    "# Validation portion.\n",
    "val_forecast = all_forecast[PARAMETERS.SPLIT_TIME - PARAMETERS.WINDOW_SIZE:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(series_valid, label=\"Validation set\")\n",
    "plt.plot(val_forecast, label=\"Predicted NDVI\")\n",
    "plt.xlabel(\"Days after planting\")\n",
    "plt.ylabel(\"NDVI\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = compute_metrics(series_valid, val_forecast)\n",
    "print(f\"mse: {mse:5f}, mae: {mae:5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the forecast of the model.\n",
    "new_forecast = []\n",
    "\n",
    "for i in range(PARAMETERS.PREDICT_STEPS):\n",
    "  new_forecast_series = PARAMETERS.SERIES[-PARAMETERS.WINDOW_SIZE:]  \n",
    "  pred = model.predict(new_forecast_series[np.newaxis])\n",
    "  new_forecast.append(pred.reshape(-1))\n",
    "  PARAMETERS.SERIES = np.append(PARAMETERS.SERIES, pred)\n",
    "\n",
    "# Crete the new time vector.\n",
    "new_time = [i for i in range(len(PARAMETERS.TIME) + 1, len(PARAMETERS.TIME) + PARAMETERS.PREDICT_STEPS + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(PARAMETERS.TIME[:300], PARAMETERS.SERIES[:300], label=\"last 400 points of time series\")\n",
    "plt.plot(new_time, new_forecast, color=\"red\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venvpgc': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "458324898a307e82937a0201a3cb78a6e01bf2fa4d39f3dd0863d1bd1c8ab461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
